{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8cdb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import wget\n",
    "from extract_articles_pisrs import process_pdf\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "\n",
    "FILE_EXTENSIONS = [\"docx\", \"doc\", \"pdf\", \"zip\", \"xlsx\"]\n",
    "ROOT_URL = \"https://www.fu.gov.si\"\n",
    "MAIN_URL=ROOT_URL+\"/podrocja\"\n",
    "METADATA_DIR = \"/Users/juankostelec/Google_drive/Projects/tax_backend/data\"\n",
    "RAW_DATA_DIR = \"/Users/juankostelec/Google_drive/Projects/tax_backend/data/raw_files\"\n",
    "PROCESSED_DATA_DIR = \"/Users/juankostelec/Google_drive/Projects/tax_backend/data/processed_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e68ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(MAIN_URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "div_content = soup.find(\"div\", id=\"content\")\n",
    "podrocja_elements = div_content.find_all(\"div\", class_=\"card dark\")\n",
    "\n",
    "data_links = []\n",
    "for group_idx, podrocje in enumerate(podrocja_elements):\n",
    "    \n",
    "    anchors = podrocje.find_all(\"a\")\n",
    "    for podrocje_idx, anchor in enumerate(anchors):\n",
    "        podrocje_name = anchor.text\n",
    "        \n",
    "        # Get the text inside the <em> element (if it exists)\n",
    "        em_text = None\n",
    "        em_element = anchor.find(\"em\")\n",
    "        if em_element:\n",
    "            em_text = em_element.text.strip()\n",
    "\n",
    "        # Get the entire text of the anchor\n",
    "        full_text = anchor.text\n",
    "\n",
    "        # Subtract the <em> text from the full text to get the remaining text\n",
    "        if em_text:\n",
    "            remaining_text = full_text.replace(em_text, \"\").strip()\n",
    "        else:\n",
    "            remaining_text = full_text.strip()\n",
    "\n",
    "        podrocje_name = remaining_text\n",
    "        podrocje_description = em_text\n",
    "\n",
    "        href_value = anchor.get(\"href\")\n",
    "        data_links.append([group_idx, podrocje_idx, podrocje_name, podrocje_description, href_value])\n",
    "\n",
    "# Now we have all the links to the data we need to scrape\n",
    "df = pd.DataFrame(data_links, columns=[\"group_idx\", \"podrocje_idx\", \"podrocje_name\", \"podrocje_description\", \"href\"])\n",
    "\n",
    "main_table = df.query(\"href == '#'\")\\\n",
    "    .rename(columns={\"podrocje_name\":\"group\",\n",
    "                     \"podrocje_description\": \"group_description\"})\\\n",
    "    .drop(columns=[\"href\",\"podrocje_idx\"])  # This gives the Podrocje id, podrocje name\n",
    "df = pd.merge(df, main_table, on=\"group_idx\", how=\"inner\").query(\"href != '#'\").drop(columns=[\"podrocje_description\"])\n",
    "\n",
    "# Convert HREFs to full URLs, add a flag if the URL links to final source, or a new webpage\n",
    "df[\"is_final_source\"] = df[\"href\"].apply(lambda x: x.startswith(\"http\"))\n",
    "df[\"url\"] = df[\"href\"].apply(lambda x: ROOT_URL+x if not x.startswith(\"http\") else x)\n",
    "df[\"href_is_file\"] = df[\"url\"].apply(lambda x: x.endswith(\".pdf\") or x.endswith(\".docx\") or x.endswith(\".doc\") or x.endswith(\".xlsx\") or x.endswith(\".xls\") or x.endswith(\".zip\"))\n",
    "df[\"href_type\"] = df[[\"is_final_source\", \"href_is_file\"]].apply(lambda x: \"file\" if x[0] and x[1] else \"website_source\" if x[0] else \"website_details\", axis=1)\n",
    "\n",
    "df.to_csv(os.path.join(METADATA_DIR, \"data_links.csv\"), index=False)\n",
    "driver.close()\n",
    "\n",
    "\n",
    "# We need to consider 3 cases:\n",
    "# 1. The URL links to a final source, and the source is a file (e.g. a PDF file)\n",
    "# 2. The URL links to a final source, and the source is a webpage\n",
    "# 3. The URL links to a new webpage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22dc78af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scraping 0/136: https://www.fu.gov.si/davki_in_druge_dajatve/poslovanje_z_nami/vpis_v_davcni_register_in_davcna_stevilka/\n",
      "Started scraping 1/136: https://www.fu.gov.si/davki_in_druge_dajatve/poslovanje_z_nami/davcni_postopek/\n",
      "Started scraping 2/136: https://www.fu.gov.si/davki_in_druge_dajatve/poslovanje_z_nami/podelitev_statusa_zaradi_spodbujanja_prostovoljnega_izpolnjevanja_obveznosti/\n",
      "Started scraping 3/136: https://www.fu.gov.si/davki_in_druge_dajatve/poslovanje_z_nami/apa_sporazum/\n",
      "Started scraping 4/136: https://www.fu.gov.si/davki_in_druge_dajatve/poslovanje_z_nami/e_davki/\n",
      "Started scraping 5/136: https://www.fu.gov.si/davki_in_druge_dajatve/poslovanje_z_nami/vrocanje/\n",
      "Started scraping 6/136: https://www.fu.gov.si/navodila_pojasnila_in_smernice/\n",
      "Started scraping 7/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/letna_odmera_dohodnine/\n",
      "Started scraping 8/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/dohodnina_dohodek_iz_zaposlitve/\n",
      "Started scraping 9/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/dohodnina_dohodek_iz_dejavnosti/\n",
      "Started scraping 10/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/dohodnina_dohodek_iz_osnovne_kmetijske_in_osnovne_gozdarske_dejavnosti/\n",
      "Started scraping 11/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/dohodnina_dohodek_iz_oddajanja_premozenja_v_najem_in_iz_prenosa_premozenjske_pravice/\n",
      "Started scraping 12/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/dohodnina_dohodek_iz_kapitala/\n",
      "Started scraping 13/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/dohodnina_drugi_dohodki/\n",
      "Started scraping 14/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/dohodnina/rek_obrazci/\n",
      "Started scraping 15/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_dohodkov_pravnih_oseb_ddpo/\n",
      "Started scraping 16/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davcni_odtegljaj_od_dohodkov_iz_nematerializiranih_financnih_instrumentov/\n",
      "Started scraping 17/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_dodano_vrednost_ddv/\n",
      "Started scraping 18/136: https://www.fu.gov.si/drugo/posebna_podrocja/e_trgovanje/\n",
      "Started scraping 19/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/nadomestilo_za_uporabo_stavbnega_zemljisca_nusz/\n",
      "Started scraping 20/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_promet_nepremicnin/\n",
      "Started scraping 21/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_dediscine_in_darila/\n",
      "Started scraping 22/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_vodna_plovila_in_dodatni_davek_od_plovil/\n",
      "Started scraping 23/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_motorna_vozila_dmv/\n",
      "Started scraping 24/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_premozenja/\n",
      "Started scraping 25/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_dobicka_od_odsvojitve_izvedenih_financnih_instrumentov/\n",
      "Started scraping 26/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_financne_storitve/\n",
      "Started scraping 27/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_prometa_zavarovalnih_poslov/\n",
      "Started scraping 28/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/pozarna_taksa/\n",
      "Started scraping 29/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/koncesijska_dajatev_ter_dodatna_koncesijska_dajatev_za_studentske_servise/\n",
      "Started scraping 30/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_dohodkov_clanov_poslovodstev_in_nadzornih_organov_v_casu_financne_in_gospodarske_krize/\n",
      "Started scraping 31/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/pribitek_k_cestnini_in_taksa_na_pretovor/\n",
      "Started scraping 32/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/solidarnostni_prispevek_po_znpovce/\n",
      "Started scraping 33/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/prispevki_za_socialno_varnost/\n",
      "Started scraping 34/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/prispevki_za_socialno_varnost/osnove_za_placilo_ter_zneski_prispevkov_za_socialno_varnost/\n",
      "Started scraping 35/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/trosarine_ztro_1/\n",
      "Started scraping 36/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/okoljske_dajatve/\n",
      "Started scraping 37/136: https://www.fu.gov.si/carina/poslovanje_z_nami/merilo_poklicne_kvalifikacije/\n",
      "Started scraping 38/136: https://www.fu.gov.si/carina/poslovanje_z_nami/registracija_eori/\n",
      "Started scraping 39/136: https://www.fu.gov.si/carina/poslovanje_z_nami/carinski_predpisi/\n",
      "Started scraping 40/136: https://www.fu.gov.si/navodila_pojasnila_in_smernice/\n",
      "Started scraping 41/136: https://www.fu.gov.si/carina/poslovanje_z_nami/pooblasceni_gospodarski_subjekt_aeo/\n",
      "Started scraping 42/136: https://www.fu.gov.si/carina/poslovanje_z_nami/centralizirano_carinjenje/\n",
      "Started scraping 43/136: https://www.fu.gov.si/carina/poslovanje_z_nami/poenostavitve/\n",
      "Started scraping 44/136: https://www.fu.gov.si/carina/poslovanje_z_nami/intrastat/\n",
      "Started scraping 45/136: https://www.fu.gov.si/carina/poslovanje_z_nami/e_carina/\n",
      "Started scraping 46/136: https://www.fu.gov.si/carina/poslovanje_z_nami/sodelovanje_gospodarstva_s_furs_na_podrocju_carin_trosarin_in_okoljskih_dajatev/\n",
      "Started scraping 47/136: https://www.fu.gov.si/carina/podrocja/potniki/\n",
      "Started scraping 48/136: https://www.fu.gov.si/carina/podrocja/postni_promet/\n",
      "Started scraping 49/136: https://www.fu.gov.si/drugo/posebna_podrocja/e_trgovanje/\n",
      "Started scraping 50/136: https://www.fu.gov.si/carina/podrocja/uvoz_blaga/\n",
      "Started scraping 51/136: https://www.fu.gov.si/carina/podrocja/izvoz_blaga/\n",
      "Started scraping 52/136: https://www.fu.gov.si/carina/podrocja/tranzit_in_status_blaga/\n",
      "Started scraping 53/136: https://www.fu.gov.si/carina/podrocja/carinski_dolg_in_zavarovanje/\n",
      "Started scraping 54/136: https://www.fu.gov.si/carina/podrocja/nomenklatura_uvrscanje_in_taric/\n",
      "Started scraping 55/136: https://www.fu.gov.si/carina/podrocja/poreklo_blaga/\n",
      "Started scraping 56/136: https://www.fu.gov.si/carina/podrocja/carinska_vrednost_blaga/\n",
      "Started scraping 57/136: https://www.fu.gov.si/carina/podrocja/tarifni_ukrepi_in_protidamping/\n",
      "Started scraping 58/136: https://www.fu.gov.si/carina/podrocja/carinski_laboratorij/\n",
      "Started scraping 59/136: https://www.fu.gov.si/carina/podrocja/izpolnjevanje_carinske_deklaracije_in_drugih_obrazcev_ata_tir/\n",
      "Started scraping 60/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/blago_z_dvojno_rabo/\n",
      "Started scraping 61/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/omejevalni_ukrepi/\n",
      "Started scraping 62/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/orozje_in_strelivo/\n",
      "Started scraping 63/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/eksplozivi_in_pirotehnicni_izdelki/\n",
      "Started scraping 64/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/radioaktivne_in_jedrske_snovi/\n",
      "Started scraping 65/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/mucilne_naprave/\n",
      "Started scraping 66/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/surovi_diamanti_in_proces_kimberley/\n",
      "Started scraping 67/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/varnost_nezivilskih_proizvodov/\n",
      "Started scraping 68/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/predhodne_sestavine_za_droge/\n",
      "Started scraping 69/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/zdravila/\n",
      "Started scraping 70/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/nevarne_kemikalije/\n",
      "Started scraping 71/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/zivila_nezivalskega_izvora/\n",
      "Started scraping 72/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/ekoloski_proizvodi/\n",
      "Started scraping 73/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/kakovost_sadja_in_zelenjave/\n",
      "Started scraping 74/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/odpadki/\n",
      "Started scraping 75/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/ozonu_skodljive_snovi/\n",
      "Started scraping 76/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/gensko_spremenjeni_organizmi_gso/\n",
      "Started scraping 77/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/ribiski_proizvodi/\n",
      "Started scraping 78/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/varstvo_zivalskih_in_rastlinskih_vrst_cites/\n",
      "Started scraping 79/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/zivali_in_zivalski_proizvodi/\n",
      "Started scraping 80/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/krma_nezivalskega_izvora/\n",
      "Started scraping 81/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/pasje_in_macje_krzno/\n",
      "Started scraping 82/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/zdravstveno_varstvo_rastlin_semenski_material_kmetijskih_rastlin_in_gozdni_reprodukcijski_material/\n",
      "Started scraping 83/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/lesen_pakirni_material_lpm/\n",
      "Started scraping 84/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/fitofarmacevtska_sredstva_ffs/\n",
      "Started scraping 85/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/prepoved_trgovine_z_lesom_flegt/\n",
      "Started scraping 86/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/varstvo_pravic_intelektualne_lastnine_ipr/\n",
      "Started scraping 87/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/tekstil_jeklo_aluminij_in_les/\n",
      "Started scraping 88/136: https://www.fu.gov.si/carina/prepovedi_in_omejitve/predmeti_kulturne_dediscine/\n",
      "Started scraping 89/136: https://www.fu.gov.si/drugo/posebna_podrocja/igre_na_sreco/\n",
      "Started scraping 90/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_na_dobitke_od_iger_na_sreco/\n",
      "Started scraping 91/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_iger_na_sreco_in_koncesijska_dajatev/\n",
      "Started scraping 92/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/davek_od_sreck/\n",
      "Started scraping 93/136: https://www.fu.gov.si/nadzor/podrocja/nadzor_iger_na_sreco/\n",
      "Started scraping 94/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/placevanje_davkov_in_drugih_dajatev/\n",
      "Started scraping 95/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/zavarovanje_placila_carinskih_in_trosarinskih_obveznosti/\n",
      "Started scraping 96/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/odpisi_odlogi_in_obrocno_placevanje/\n",
      "Started scraping 97/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/opominjanje/\n",
      "Started scraping 98/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/potrdila_in_razkritja/\n",
      "Started scraping 99/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/davcna_izvrsba/\n",
      "Started scraping 100/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/izvrsba_nedavcnih_obveznosti/\n",
      "Started scraping 101/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/insolvencni_postopki_in_drugi_nacini_prenehanja_pravne_osebe/\n",
      "Started scraping 102/136: https://www.fu.gov.si/placevanje_in_izvrsba/podrocja/ravnanje_z_blagom/\n",
      "Started scraping 103/136: https://www.fu.gov.si/nadzor/podrocja/financni_nadzor/\n",
      "Started scraping 104/136: https://www.fu.gov.si/nadzor/podrocja/nadzor_nad_delom_in_zaposlovanjem_na_crno/\n",
      "Started scraping 105/136: https://www.fu.gov.si/nadzor/podrocja/nadzor_nad_prevozi_v_cestnem_prometu/\n",
      "Started scraping 106/136: https://www.fu.gov.si/nadzor/podrocja/davcne_blagajne_in_vezane_knjige_racunov_vkr/\n",
      "Started scraping 107/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/mednarodno_obdavcenje/\n",
      "Started scraping 108/136: https://www.fu.gov.si/davki_in_druge_dajatve/podrocja/mednarodno_obdavcenje/postopek_skupnega_dogovarjanja_map_postopek/\n",
      "Started scraping 109/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/\n",
      "Started scraping 110/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/fatca/\n",
      "Started scraping 111/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/oecd_standard_avtomaticne_izmenjave_informacij_o_financnih_racunih_in_direktiva_sveta_2014/107/eu/\n",
      "Started scraping 112/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/izmenjava_davcnih_stalisc/\n",
      "Started scraping 113/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/cbcr/\n",
      "Started scraping 114/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/izmenjava_informacij_o_cezmejnih_aranzmajih/\n",
      "Started scraping 115/136: https://www.fu.gov.si/nadzor/podrocja/mednarodna_izmenjava/izmenjava_podatkov_ki_jih_sporocajo_operaterji_platform_dpi_model_rules/dac7/\n",
      "Started scraping 116/136: https://www.fu.gov.si/drugo/pkp10_novice_ter_pogosta_vprasanja_in_odgovori_v_zvezi_z_ukrepi_na_davcnem_podrocju/\n",
      "Started scraping 117/136: https://www.fu.gov.si/carina/poslovanje_z_nami/ukrepi_na_carinskem_podrocju_v_casu_covid_19/\n",
      "Started scraping 118/136: https://www.fu.gov.si/e_storitve/seznam_upravicencev_do_mtd_in_oprostitve_placila_psv/\n",
      "Started scraping 119/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8747\n",
      "Started scraping 120/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8748\n",
      "Started scraping 121/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8750\n",
      "Started scraping 122/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8751\n",
      "Started scraping 123/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8734\n",
      "Started scraping 124/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8752\n",
      "Started scraping 125/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8753\n",
      "Started scraping 126/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8742\n",
      "Started scraping 127/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8755\n",
      "Started scraping 128/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8741\n",
      "Started scraping 129/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8737\n",
      "Started scraping 130/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8736\n",
      "Started scraping 131/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8731\n",
      "Started scraping 132/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8730\n",
      "Started scraping 133/136: https://www.fu.gov.si/drugo/posebna_podrocja/turisticni_bon_in_bon21/#c8729\n",
      "Started scraping 134/136: https://www.fu.gov.si/drugo/posebna_podrocja/poplave_2023/poplave_2023_novice/\n",
      "Started scraping 135/136: https://www.fu.gov.si/drugo/posebna_podrocja/poplave_2023/poplave_2023_pogosta_vprasanja_in_odgovori_v_zvezi_z_davcnimi_vsebinami_v_povezavi_s_poplavami/\n"
     ]
    }
   ],
   "source": [
    "# Loop through each unique website and extract the HTML using Selenium and BeautifulSoup\n",
    "website_data = []\n",
    "href_data = []\n",
    "new_websites = df.query(\"is_final_source == False and href_is_file == False\")[\"url\"].values.tolist()\n",
    "cleaned_websites = [\"/\".join(x.split(\"/\")[:-1]) if x.split(\"/\")[-1].startswith(\"#\") else \"/\".join(x.split(\"/\")) for x in new_websites]\n",
    "for idx, (url, raw_url) in enumerate(zip(cleaned_websites, new_websites)):\n",
    "    if idx%10 == 0:\n",
    "        print(\"Started scraping {}/{}: {}\".format(idx, len(new_websites), raw_url))\n",
    "    \n",
    "    # Open the website using Selenium\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    # Extract the HTML using BeautifulSoup\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Close the Selenium driver\n",
    "    driver.close()\n",
    "\n",
    "    # Get the text in the <h1> element  --> this gives the title of the page\n",
    "    h1_text = None\n",
    "    h1_element = soup.find(\"h1\")\n",
    "    if h1_element:\n",
    "        h1_text = h1_element.text.strip()\n",
    "\n",
    "    opis_text = None\n",
    "    zakonodaja_type = None\n",
    "    for h2 in soup.find_all('h2'):\n",
    "        if h2.find(\"a\") is None:\n",
    "            continue\n",
    "        a_text = h2.find('a').text.strip()\n",
    "        \n",
    "        # Exclude the text from the <i> elements to get only \"Zakonodaja\"\n",
    "        for i in h2.find_all('i'):\n",
    "            a_text = a_text.replace(i.text, '').strip()\n",
    "        if \"Opis\" in a_text:\n",
    "            opis_parent_element = h2.parent\n",
    "            if opis_parent_element:\n",
    "                opis_p_elements = opis_parent_element.find_all(\"p\")\n",
    "                opis_text = \" \".join([x.text.strip() for x in opis_p_elements])\n",
    "        elif \"Zakonodaja\" in a_text:\n",
    "            zakonodaja_sister_elements = h2.find_next_siblings()\n",
    "            for element in zakonodaja_sister_elements:\n",
    "                a_elements = element.find_all(\"a\", href=True)                \n",
    "                for a in a_elements:\n",
    "                    # This is an anchor element, so extract the text and the href and save them as separate values\n",
    "                    zakonodaja_text = a.text.strip()\n",
    "                    zakonodaja_href = a.get(\"href\")\n",
    "                    href_data.append([raw_url, zakonodaja_text, zakonodaja_href])\n",
    "\n",
    "        elif \"Podrobnejši opisi\" in a_text:\n",
    "            podrobnejsi_opisi_sister_elements = h2.find_next_siblings()\n",
    "            for element in podrobnejsi_opisi_sister_elements:\n",
    "                a_elements = element.find_all(\"a\", href=True)                \n",
    "                for a in a_elements:\n",
    "                    # This is an anchor element, so extract the text and the href and save them as separate values\n",
    "                    podrobnejsi_opisi_text = a.text.strip()\n",
    "                    podrobnejsi_opisi_href = a.get(\"href\")\n",
    "                    href_data.append([raw_url, podrobnejsi_opisi_text, podrobnejsi_opisi_href])\n",
    "    website_data.append([raw_url, h1_text, opis_text])\n",
    "\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df_website_data = pd.DataFrame(website_data, columns=[\"url\", \"title\", \"opis\"])\n",
    "df_website_data.to_csv(os.path.join(METADATA_DIR, \"website_data.csv\"), index=False)\n",
    "\n",
    "href_data = pd.DataFrame(href_data, columns=[\"url\", \"source_desc\", \"source_href\"])\n",
    "href_data.to_csv(os.path.join(METADATA_DIR, \"href_data.csv\"), index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c17f5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the tables into a single one\n",
    "df = pd.read_csv(os.path.join(METADATA_DIR, \"data_links.csv\"))\n",
    "df_hrefs = pd.read_csv(os.path.join(METADATA_DIR, \"href_data.csv\"))\n",
    "df_podrocja = pd.read_csv(os.path.join(METADATA_DIR, \"website_data.csv\"))\n",
    "\n",
    "\n",
    "df_sources = df.query(\"href_type != 'website_details'\").rename(\n",
    "    columns={\n",
    "        \"group\":\"group_name\",\n",
    "        \"group_description\":\"group_desc\",\n",
    "        \"podrocje_name\":\"podrocje_name\",\n",
    "        \"url\": \"file_url\"}\n",
    ")\n",
    "df_sources = df_sources[[\"group_name\", \"group_desc\", \"podrocje_name\", \"file_url\"]].drop_duplicates()\n",
    "\n",
    "df_links = df.query(\"href_type == 'website_details'\").rename(\n",
    "    columns={\n",
    "        \"group\":\"group_name\",\n",
    "        \"group_description\":\"group_desc\",\n",
    "        \"podrocje_name\":\"podrocje_name\",\n",
    "        \"url\":\"podrocje_url\"})\n",
    "df_links = df_links[[\"group_name\", \"group_desc\", \"podrocje_name\", \"podrocje_url\"]].drop_duplicates()\n",
    "\n",
    "df_hrefs = df_hrefs.rename(\n",
    "    columns={\n",
    "        \"url\":\"podrocje_url\",\n",
    "        \"source_desc\":\"file_desc\",\n",
    "        \"source_href\":\"file_url\"})\n",
    "df_hrefs = df_hrefs[[\"podrocje_url\", \"file_desc\", \"file_url\"]].drop_duplicates()\n",
    "\n",
    "df_podrocja = df_podrocja.rename(\n",
    "    columns={\n",
    "        \"url\":\"podrocje_url\",\n",
    "        \"title\":\"podrocje_title\",\n",
    "        \"opis\":\"podrocje_opis\"})\n",
    "df_podrocja = df_podrocja[[\"podrocje_url\", \"podrocje_title\", \"podrocje_opis\"]].drop_duplicates()\n",
    "\n",
    "df_enriched_links = pd.merge(df_links, df_hrefs, on=\"podrocje_url\", how=\"left\")\n",
    "# Check which podrocje has no files:\n",
    "df_enriched_links = pd.merge(df_enriched_links, df_podrocja, on=\"podrocje_url\", how=\"left\")\n",
    "df_sources[\"podrocje_url\"] = [None] * len(df_sources)\n",
    "df_sources[\"file_desc\"] = [None] * len(df_sources)\n",
    "df_sources[\"podrocje_opis\"] = [None] * len(df_sources)\n",
    "df_sources = df_sources[['group_name', 'group_desc', 'podrocje_name', 'podrocje_url',\n",
    "       'file_desc', 'file_url', 'podrocje_opis']]\n",
    "df_enriched_links = df_enriched_links[['group_name', 'group_desc', 'podrocje_name', 'podrocje_url',\n",
    "       'file_desc', 'file_url', 'podrocje_opis']]\n",
    "\n",
    "\n",
    "\n",
    "def get_file_type(href):\n",
    "\n",
    "    for file_extension in FILE_EXTENSIONS:\n",
    "        if str(href).endswith(file_extension):\n",
    "            return file_extension\n",
    "    if str(href).startswith(\"/\"):\n",
    "        # relative path to a website\n",
    "        return \"website\"\n",
    "    elif str(href).startswith(\"http\"):\n",
    "        return \"website\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# https://www.fu.gov.si/carina/poslovanje_z_nami/carinski_predpisi/#c1496\n",
    "df_combined = pd.concat([df_enriched_links, df_sources], axis=0)\n",
    "df_combined[\"file_type\"] = df_combined[\"file_url\"].apply(lambda x: get_file_type(x))\n",
    "df_combined = df_combined.drop_duplicates()\n",
    "updated_urls = []\n",
    "for url in df_combined[\"file_url\"]:\n",
    "    if str(url).startswith(\"/\"):\n",
    "        updated_urls.append(os.path.join(\"https://www.fu.gov.si/\", url))\n",
    "    else:\n",
    "        updated_urls.append(url)\n",
    "df_combined[\"file_url\"] = updated_urls\n",
    "df_combined.to_csv(os.path.join(METADATA_DIR, \"furs_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a053b4",
   "metadata": {},
   "source": [
    "# Extract and encode data from PISRS.SI domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1564 521 578 139 326\n"
     ]
    }
   ],
   "source": [
    "df_pisrs = df_combined[df_combined[\"file_url\"].str.startswith(\"http://www.pisrs.si\") == True ].copy()\n",
    "df_furs = df_combined[df_combined[\"file_url\"].str.startswith(\"https://www.fu.gov.si\") == True].copy()\n",
    "df_eurlax = df_combined[df_combined[\"file_url\"].str.startswith(\"http://eur-lex.europa.eu\") == True].copy()   \n",
    "df_other = df_combined[~df_combined.index.isin(df_pisrs.index.tolist() + df_furs.index.tolist() + df_eurlax.index.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8647&idPredpisaChng=ZAKO6792&type=pdf\n",
      "H1 text:  Zakon o finančni upravi (ZFU)\n",
      "Source name:  Zakon o finančni upravi (ZFU).pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8346&idPredpisaChng=ZAKO1603&type=pdf\n",
      "H1 text:  Zakon o splošnem upravnem postopku (ZUP)\n",
      "Source name:  Zakon o splošnem upravnem postopku (ZUP).pdf\n",
      "Downloading pdf/doc file of law: Zakon o splošnem upravnem postopku (ZUP).pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8346&idPredpisaChng=ZAKO1603&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV12962&type=pdf\n",
      "H1 text:  Pravilnik o vsebini, obliki in načinu dostave podatkov o plačilu dohodka osebi, ki se po drugem odstavku 58. člena Zakona o davčnem postopku šteje za plačnika davk\n",
      "Source name:  Pravilnik o vsebini, obliki in načinu dostave podatkov o plačilu dohodka osebi, ki se po drugem odstavku 58. člena Zakona o davčnem postopku šteje za plačnika davk.pdf\n",
      "Downloading pdf/doc file of law: Pravilnik o vsebini, obliki in načinu dostave podatkov o plačilu dohodka osebi, ki se po drugem odstavku 58. člena Zakona o davčnem postopku šteje za plačnika davk.pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV12962&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV10416&idPredpisaChng=PRAV9885&type=pdf\n",
      "H1 text:  Pravilnik o obliki in načinu dostave podatkov o dohodku od prihrankov v obliki plačil obrest\n",
      "Source name:  Pravilnik o obliki in načinu dostave podatkov o dohodku od prihrankov v obliki plačil obrest.pdf\n",
      "Downloading pdf/doc file of law: Pravilnik o obliki in načinu dostave podatkov o dohodku od prihrankov v obliki plačil obrest.pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV10416&idPredpisaChng=PRAV9885&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV14524&idPredpisaChng=PRAV8815&type=pdf\n",
      "H1 text:  Pravilnik o vsebini in obliki obračuna davčnih odtegljajev ter o načinu predložitve davčnemu organu\n",
      "Source name:  Pravilnik o vsebini in obliki obračuna davčnih odtegljajev ter o načinu predložitve davčnemu organu.pdf\n",
      "Downloading pdf/doc file of law: Pravilnik o vsebini in obliki obračuna davčnih odtegljajev ter o načinu predložitve davčnemu organu.pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV14524&idPredpisaChng=PRAV8815&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8647&idPredpisaChng=ZAKO6792&type=pdf\n",
      "H1 text:  Zakon o finančni upravi (ZFU)\n",
      "Source name:  Zakon o finančni upravi (ZFU).pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV11987&type=pdf\n",
      "H1 text:  Pravilnik o podelitvi statusa zaradi spodbujanja prostovoljnega izpolnjevanja obveznost\n",
      "Source name:  Pravilnik o podelitvi statusa zaradi spodbujanja prostovoljnega izpolnjevanja obveznost.pdf\n",
      "Downloading pdf/doc file of law: Pravilnik o podelitvi statusa zaradi spodbujanja prostovoljnega izpolnjevanja obveznost.pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV11987&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ODLU2001&idPredpisaChng=ZAKO4703&type=pdf\n",
      "H1 text:  Zakon o davčnem postopku (ZDavP-2)\n",
      "Source name:  Zakon o davčnem postopku (ZDavP-2).pdf\n",
      "Downloading pdf/doc file of law: Zakon o davčnem postopku (ZDavP-2).pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ODLU2001&idPredpisaChng=ZAKO4703&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV15076&idPredpisaChng=PRAV7927&type=pdf\n",
      "H1 text:  Pravilnik o izvajanju Zakona o davčnem postopk\n",
      "Source name:  Pravilnik o izvajanju Zakona o davčnem postopk.pdf\n",
      "Downloading pdf/doc file of law: Pravilnik o izvajanju Zakona o davčnem postopk.pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=PRAV15076&idPredpisaChng=PRAV7927&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ODLU2001&idPredpisaChng=ZAKO4703&type=pdf\n",
      "H1 text:  Zakon o davčnem postopku (ZDavP-2)\n",
      "Source name:  Zakon o davčnem postopku (ZDavP-2).pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8346&idPredpisaChng=ZAKO1603&type=pdf\n",
      "H1 text:  Zakon o splošnem upravnem postopku (ZUP)\n",
      "Source name:  Zakon o splošnem upravnem postopku (ZUP).pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8674&idPredpisaChng=ZAKO4701&type=pdf\n",
      "H1 text:  Zakon o davku na dodano vrednost (ZDDV-1)\n",
      "Source name:  Zakon o davku na dodano vrednost (ZDDV-1).pdf\n",
      "Downloading pdf/doc file of law: Zakon o davku na dodano vrednost (ZDDV-1).pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8674&idPredpisaChng=ZAKO4701&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=URED8910&idPredpisaChng=URED6937&type=pdf\n",
      "H1 text:  Uredba o upravnem poslovanju\n",
      "Source name:  Uredba o upravnem poslovanju.pdf\n",
      "Downloading pdf/doc file of law: Uredba o upravnem poslovanju.pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=URED8910&idPredpisaChng=URED6937&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ODLU2001&idPredpisaChng=ZAKO4703&type=pdf\n",
      "H1 text:  Zakon o davčnem postopku (ZDavP-2)\n",
      "Source name:  Zakon o davčnem postopku (ZDavP-2).pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8819&idPredpisaChng=ZAKO6280&type=pdf\n",
      "H1 text:  Zakon o pokojninskem in invalidskem zavarovanju (ZPIZ-2)\n",
      "Source name:  Zakon o pokojninskem in invalidskem zavarovanju (ZPIZ-2).pdf\n",
      "Downloading pdf/doc file of law: Zakon o pokojninskem in invalidskem zavarovanju (ZPIZ-2).pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO8819&idPredpisaChng=ZAKO6280&type=pdf\n",
      "http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO6388&idPredpisaChng=ZAKO1431&type=pdf\n",
      "H1 text:  Zakon o pokojninskem in invalidskem zavarovanju (ZPIZ-1)\n",
      "Source name:  Zakon o pokojninskem in invalidskem zavarovanju (ZPIZ-1).pdf\n",
      "Downloading pdf/doc file of law: Zakon o pokojninskem in invalidskem zavarovanju (ZPIZ-1).pdf from website http://www.pisrs.si/Pis.web/npbDocPdf?idPredpisa=ZAKO6388&idPredpisaChng=ZAKO1431&type=pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/juankostelec/Google_drive/Projects/tax_backend/src/data/scrape_furs.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juankostelec/Google_drive/Projects/tax_backend/src/data/scrape_furs.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juankostelec/Google_drive/Projects/tax_backend/src/data/scrape_furs.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChrome()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juankostelec/Google_drive/Projects/tax_backend/src/data/scrape_furs.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     driver\u001b[39m.\u001b[39;49mget(file_url)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juankostelec/Google_drive/Projects/tax_backend/src/data/scrape_furs.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Extract the HTML using BeautifulSoup\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juankostelec/Google_drive/Projects/tax_backend/src/data/scrape_furs.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     html \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:353\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: url})\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m    340\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[0;32m--> 342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:297\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    295\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    296\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:318\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    315\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 318\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    319\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/taxGPT/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, row in df_pisrs[[\"file_url\"]].iterrows():\n",
    "    file_url = row[\"file_url\"]\n",
    "    # Open the website using Selenium\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(file_url)\n",
    "\n",
    "        # Extract the HTML using BeautifulSoup\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # Extract the law title if available, this is the text in the <h1> element\n",
    "        h1_text = None\n",
    "        h1_element = soup.find(\"h1\")\n",
    "        if h1_element:\n",
    "            h1_text = h1_element.text.strip()[:-1].strip()\n",
    "\n",
    "        # Extract the URL from the website containing the link to the actual pdf/doc file        \n",
    "        div_element = soup.find(\"div\", id=\"fileBtns\")\n",
    "        if div_element:        \n",
    "            a_elements = div_element.find_all(\"a\", href=True)\n",
    "            for a in a_elements:\n",
    "                href_value = a.get(\"href\")\n",
    "                complete_url_path = os.path.join(file_url.rsplit(\"/\", maxsplit=1)[0], href_value)\n",
    "                if href_value.endswith(\"pdf\"):\n",
    "                    # Use the actual name of the law for the file name, with the correct extension\n",
    "                    if h1_text:\n",
    "                        source_name = h1_text + \".pdf\"\n",
    "                    else:\n",
    "                        source_name = href_value.split(\"/\")[-1]\n",
    "\n",
    "                    # Download file if it does not already exist  \n",
    "                    if not os.path.exists(os.path.join(RAW_DATA_DIR, source_name)):\n",
    "                        print(f\"Downloading pdf/doc file of law: {source_name} from website {complete_url_path}\" )\n",
    "                        wget.download(complete_url_path, os.path.join(RAW_DATA_DIR, source_name)) \n",
    "\n",
    "                        # Process file and extract the articles from the law\n",
    "                        process_pdf(os.path.join(RAW_DATA_DIR, source_name), PROCESSED_)))          \n",
    "    except Exception as e:\n",
    "        print(\"Tried to get the website html, but did not work. Exception: \", e)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.close()\n",
    "\n",
    "\n",
    "# Now loop over the files and encode them and add to a vector database\n",
    "for \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and encode data from fu.gov.si domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dae843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically I have data coming from 3 domains:\n",
    "# fu.gov.si (mainzl doc files, and ad hoc created things it seem)\n",
    "# pisrs.si (mainly pdf files, nicely structured, can also access the html of the website to parse the law instead of the PDF)\n",
    "# eur-lex.europa.eu (don't always have the pdf available,  nicely structured, can also access the html of the website to parse the law instead of the PDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
